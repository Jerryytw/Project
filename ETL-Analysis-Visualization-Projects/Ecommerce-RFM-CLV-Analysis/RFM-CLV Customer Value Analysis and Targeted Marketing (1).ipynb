{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "582b6cb6-2f02-45c2-a9cb-71659f80e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/jerry/Downloads/new_retail_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05560f92-11b3-4878-b742-305544fb9c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Transaction_ID', 'Customer_ID', 'Name', 'Email', 'Phone', 'Address', 'City', 'State', 'Zipcode', 'Country', 'Age', 'Gender', 'Income', 'Customer_Segment', 'Date', 'Year', 'Month', 'Time', 'Total_Purchases', 'Amount', 'Total_Amount', 'Product_Category', 'Product_Brand', 'Product_Type', 'Feedback', 'Shipping_Method', 'Payment_Method', 'Order_Status', 'Ratings', 'products']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843aacf2-fcdd-4ac5-830a-160aa04e4fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 302010\n"
     ]
    }
   ],
   "source": [
    "total_rows = len(df)\n",
    "print(\"Total rows:\", total_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b603a937-3dca-4096-9de7-29c9f4f337d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Transaction_ID', 'Customer_ID', 'Name', 'Email', 'Phone', 'Address', 'City', 'State', 'Zipcode', 'Country', 'Age', 'Gender', 'Income', 'Customer_Segment', 'Date', 'Year', 'Month', 'Time', 'Total_Purchases', 'Amount', 'Total_Amount', 'Product_Category', 'Product_Brand', 'Product_Type', 'Feedback', 'Shipping_Method', 'Payment_Method', 'Order_Status', 'Ratings', 'products']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b622672-36c2-4973-a4e2-f301ed468d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Missing Count  Missing %\n",
      "Name                        382       0.13\n",
      "Year                        350       0.12\n",
      "Date                        359       0.12\n",
      "Phone                       362       0.12\n",
      "Total_Amount                350       0.12\n",
      "Amount                      357       0.12\n",
      "Total_Purchases             361       0.12\n",
      "Time                        350       0.12\n",
      "Shipping_Method             337       0.11\n",
      "Transaction_ID              333       0.11\n",
      "Zipcode                     340       0.11\n",
      "Email                       347       0.11\n",
      "Address                     315       0.10\n",
      "Payment_Method              297       0.10\n",
      "Income                      290       0.10\n",
      "Customer_ID                 308       0.10\n",
      "Gender                      317       0.10\n",
      "Country                     271       0.09\n",
      "Month                       273       0.09\n",
      "State                       281       0.09\n",
      "Product_Category            283       0.09\n",
      "Product_Brand               281       0.09\n",
      "City                        248       0.08\n",
      "Order_Status                235       0.08\n",
      "Customer_Segment            215       0.07\n",
      "Ratings                     184       0.06\n",
      "Age                         173       0.06\n",
      "Feedback                    184       0.06\n",
      "Product_Type                  0       0.00\n",
      "products                      0       0.00\n"
     ]
    }
   ],
   "source": [
    "missing_count = df.isnull().sum()\n",
    "missing_pct = (missing_count / len(df) * 100).round(2)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'Missing Count': missing_count,\n",
    "    'Missing %': missing_pct\n",
    "}).sort_values(by='Missing %', ascending=False)\n",
    "\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1d27285-8697-4d11-8342-c1a37b8828d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bcbb347-a19a-4777-b7c2-f563d0f64b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 293911\n"
     ]
    }
   ],
   "source": [
    "total_rows = len(df)\n",
    "print(\"Total rows:\", total_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c67cdaa-c7eb-40c6-b142-7852e322a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Customer_ID'] = df['Customer_ID'].astype(str)\n",
    "df['Transaction_ID'] = df['Transaction_ID'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2a2be46-652f-45bd-8e29-b1dacfefce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases_per_customer = (\n",
    "    df.dropna(subset=['Customer_ID'])\n",
    "      .groupby('Customer_ID')['Transaction_ID']\n",
    "      .nunique()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "620504a8-5dc7-480f-8bb7-0bb39291834a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg purchases per customer: 3.374\n",
      "Repeat purchase rate: 86.72%\n"
     ]
    }
   ],
   "source": [
    "avg_purchases_per_customer = purchases_per_customer.mean()\n",
    "repeat_rate = (purchases_per_customer >= 2).mean()  # share of customers with ≥2 purchases\n",
    "\n",
    "print(f\"Avg purchases per customer: {avg_purchases_per_customer:.3f}\")\n",
    "print(f\"Repeat purchase rate: {repeat_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd54dfd3-645b-4be3-bf33-13040695b9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payment method preference (% of orders):\n",
      "Payment_Method\n",
      "Credit Card    29.87\n",
      "Debit Card     25.43\n",
      "Cash           24.47\n",
      "PayPal         20.23\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Payment method preference (% by order count)\n",
    "payment_pref = (\n",
    "    df['Payment_Method']\n",
    "    .dropna()\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .value_counts(normalize=True)\n",
    "    .mul(100)\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "print(\"Payment method preference (% of orders):\")\n",
    "print(payment_pref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b389807c-fe5b-4a00-abc0-06218c8ce8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "# Ensure Amount is numeric\n",
    "df['Amount'] = pd.to_numeric(df['Amount'], errors='coerce')\n",
    "\n",
    "# Ensure Total_Amount is numeric if it exists\n",
    "if 'Total_Amount' in df.columns:\n",
    "    df['Total_Amount'] = pd.to_numeric(df['Total_Amount'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "075d2429-45f0-4bb7-9b85-244845f2f36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RFM Analysis (Top 10) ===\n",
      "  Customer_ID  Recency  Frequency     Monetary  R_Score  F_Score  M_Score  \\\n",
      "0     10000.0      103          4   940.297743        2        3        4   \n",
      "1     10001.0      105          5  1517.921543        2        4        5   \n",
      "2     10002.0       95          5  1117.164676        3        4        4   \n",
      "3     10003.0      228          2   266.301835        1        1        1   \n",
      "4     10004.0       31          2   460.702696        4        1        2   \n",
      "5     10005.0      246          1   439.021139        1        1        2   \n",
      "6     10006.0       16          4  1022.336464        5        3        4   \n",
      "7     10007.0       34          5  1090.912878        4        4        4   \n",
      "8     10008.0        9          5  1667.611565        5        4        5   \n",
      "9     10009.0       58          3   338.720709        3        2        1   \n",
      "\n",
      "   RFM_Score     Segment  \n",
      "0          9   Mid-Value  \n",
      "1         11   Mid-Value  \n",
      "2         11   Mid-Value  \n",
      "3          3   Low-Value  \n",
      "4          7   Low-Value  \n",
      "5          4   Low-Value  \n",
      "6         12   Mid-Value  \n",
      "7         12   Mid-Value  \n",
      "8         14  High-Value  \n",
      "9          6   Low-Value  \n"
     ]
    }
   ],
   "source": [
    "# Set reference date as the day after the last purchase\n",
    "today = df['Date'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "rfm = df.groupby('Customer_ID').agg({\n",
    "    'Date': lambda x: (today - x.max()).days,  # Recency: days since last purchase\n",
    "    'Transaction_ID': 'nunique',              # Frequency: number of purchases\n",
    "    'Amount': 'sum'                            # Monetary: total spend\n",
    "}).reset_index()\n",
    "\n",
    "rfm.rename(columns={'Date': 'Recency', 'Transaction_ID': 'Frequency', 'Amount': 'Monetary'}, inplace=True)\n",
    "\n",
    "# Assign scores (1 to 5) for R, F, and M\n",
    "rfm['R_Score'] = pd.qcut(rfm['Recency'], 5, labels=[5,4,3,2,1]).astype(int)  # lower Recency → higher score\n",
    "rfm['F_Score'] = pd.qcut(rfm['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5]).astype(int)\n",
    "rfm['M_Score'] = pd.qcut(rfm['Monetary'].rank(method='first'), 5, labels=[1,2,3,4,5]).astype(int)\n",
    "\n",
    "# Total RFM score\n",
    "rfm['RFM_Score'] = rfm[['R_Score','F_Score','M_Score']].sum(axis=1)\n",
    "\n",
    "# Segment customers based on RFM score\n",
    "def segment(row):\n",
    "    if row['RFM_Score'] >= 13:\n",
    "        return 'High-Value'\n",
    "    elif row['RFM_Score'] >= 9:\n",
    "        return 'Mid-Value'\n",
    "    else:\n",
    "        return 'Low-Value'\n",
    "\n",
    "rfm['Segment'] = rfm.apply(segment, axis=1)\n",
    "\n",
    "print(\"\\n=== RFM Analysis (Top 10) ===\")\n",
    "print(rfm.head(10))\n",
    "\n",
    "# Save RFM results\n",
    "rfm.to_csv(\"RFM_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3835fa34-0753-4776-937e-dadf9c791975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5l/qls4phs14lg3v_4wscl92_4w0000gn/T/ipykernel_67092/3130578664.py:1: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  avg_order_value = df.groupby('Customer_ID').apply(lambda x: x['Amount'].sum() / x['Transaction_ID'].nunique())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CLV Analysis (Top 10) ===\n",
      "  Customer_ID  Average_Order_Value  Purchase_Frequency_per_Year  \\\n",
      "0     10000.0           235.074436                     7.724868   \n",
      "1     10001.0           303.584309                     7.358871   \n",
      "2     10002.0           223.432935                     8.220721   \n",
      "3     10003.0           133.150918                     9.480519   \n",
      "4     10004.0           230.351348                     6.293103   \n",
      "5     10005.0           439.021139                   365.000000   \n",
      "6     10006.0           255.584116                     6.666667   \n",
      "7     10007.0           218.182576                     6.809701   \n",
      "8     10008.0           333.522313                     8.075221   \n",
      "9     10009.0           112.906903                    10.631068   \n",
      "\n",
      "             CLV CLV_Segment  \n",
      "0    5447.756762      Medium  \n",
      "1    6702.113264      Medium  \n",
      "2    5510.339278      Medium  \n",
      "3    3787.019606         Low  \n",
      "4    4348.874586         Low  \n",
      "5  480728.147533        High  \n",
      "6    5111.682321      Medium  \n",
      "7    4457.274633         Low  \n",
      "8    8079.799396      Medium  \n",
      "9    3600.962877         Low  \n"
     ]
    }
   ],
   "source": [
    "avg_order_value = df.groupby('Customer_ID').apply(lambda x: x['Amount'].sum() / x['Transaction_ID'].nunique())\n",
    "\n",
    "# Calculate purchase frequency per year\n",
    "purchase_span_days = df.groupby('Customer_ID')['Date'].agg(['min','max'])\n",
    "purchase_span_days['days'] = (purchase_span_days['max'] - purchase_span_days['min']).dt.days + 1\n",
    "purchase_span_days['purchase_count'] = df.groupby('Customer_ID')['Transaction_ID'].nunique()\n",
    "\n",
    "purchase_span_days['purchase_frequency_per_year'] = purchase_span_days['purchase_count'] / (purchase_span_days['days'] / 365)\n",
    "\n",
    "# Expected lifespan (years)\n",
    "expected_lifespan_years = 3\n",
    "\n",
    "# Calculate CLV\n",
    "clv = pd.DataFrame({\n",
    "    'Customer_ID': avg_order_value.index,\n",
    "    'Average_Order_Value': avg_order_value.values,\n",
    "    'Purchase_Frequency_per_Year': purchase_span_days['purchase_frequency_per_year'].values\n",
    "})\n",
    "clv['CLV'] = clv['Average_Order_Value'] * clv['Purchase_Frequency_per_Year'] * expected_lifespan_years\n",
    "\n",
    "# CLV segmentation\n",
    "clv['CLV_Segment'] = pd.qcut(clv['CLV'], 3, labels=['Low', 'Medium', 'High'])\n",
    "\n",
    "print(\"\\n=== CLV Analysis (Top 10) ===\")\n",
    "print(clv.head(10))\n",
    "\n",
    "# Save CLV results\n",
    "clv.to_csv(\"CLV_results.csv\", index=False)\n",
    "\n",
    "# ===================== Step 6: Merge RFM & CLV and Identify Target Customers =====================\n",
    "rfm = pd.read_csv(\"RFM_results.csv\")\n",
    "clv = pd.read_csv(\"CLV_results.csv\")\n",
    "\n",
    "merged = pd.merge(rfm, clv, on=\"Customer_ID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e98fa534-86eb-4698-b24a-5c2a4218e165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "交集客户数量: 2949\n",
      "\n",
      "=== 样例客户名单（前10条） ===\n",
      "     Customer_ID  RFM_Score           CLV  Recency  Frequency     Monetary\n",
      "66       10069.0         14  11202.670738       29          8  2127.995903\n",
      "188      10196.0         13   8333.433963       72          7  2085.261101\n",
      "195      10204.0         15   8480.939035       16          9  2687.566982\n",
      "232      10242.0         13   9121.147177       64          7  2024.144990\n",
      "248      10258.0         14   8772.831213       29          6  1554.273293\n",
      "268      10281.0         13  10710.440006       79          8  2347.493700\n",
      "333      10350.0         13  11764.978793       95          6  2256.297303\n",
      "349      10367.0         14   9135.756334       51          7  1902.239675\n",
      "353      10371.0         14   8308.775257        2          5  1570.699980\n",
      "361      10379.0         13  13431.091599       47          5  1827.609724\n"
     ]
    }
   ],
   "source": [
    "# Select customers who are both High-Value in RFM and High in CLV\n",
    "target_customers = merged[\n",
    "    (merged['Segment'] == 'High-Value') &\n",
    "    (merged['CLV_Segment'] == 'High')\n",
    "]\n",
    "\n",
    "print(f\"Number of target customers: {len(target_customers)}\")\n",
    "print(\"\\n=== Sample Target Customers (Top 10) ===\")\n",
    "print(target_customers[['Customer_ID', 'RFM_Score', 'CLV', 'Recency', 'Frequency', 'Monetary']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac926c86-061c-4e8f-ab8d-285cd31a90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save target customer list for marketing\n",
    "target_customers.to_csv(\"Target_Customers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c4965c-8102-48a5-b80f-03d0b5795414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
